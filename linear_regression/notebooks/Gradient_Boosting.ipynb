{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient_Boosting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "dH24J3TASJuF"
      },
      "source": [
        "#@title Default title text\n",
        "TRAIN_URL = 'https://raw.githubusercontent.com/JamesBarciz/ML_algorithm_exploration/master/linear_regression/cleaned_datasets/train_cleaned.csv'\n",
        "TEST_URL = 'https://raw.githubusercontent.com/JamesBarciz/ML_algorithm_exploration/master/linear_regression/test.csv'\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class Train:\n",
        "    '''\n",
        "    Class Train contains methods to perform data cleaning of a particular\n",
        "    DataFrame for the Ames Housing data set.\n",
        "    '''\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        self.df = df\n",
        "        self.cleaned = self.df.copy()\n",
        "\n",
        "    def show_stats(self, series: str):\n",
        "        \"\"\"Print stats from a Pandas Series\"\"\"\n",
        "\n",
        "            # Describe\n",
        "        descriptive_stats = self.cleaned[series].describe()\n",
        "        print('Describe Method:')\n",
        "        print(descriptive_stats)\n",
        "        print('---------------------------------------------------')\n",
        "        \n",
        "        # Numeric Columns only\n",
        "        if self.cleaned[series].dtype == 'int64':\n",
        "            mean = self.cleaned[series].mean()\n",
        "            maximum = max(self.cleaned[series])\n",
        "            minimum = min(self.cleaned[series])\n",
        "            print(f'''\n",
        "The Min/Max of column {self.cleaned[series].name}: ({minimum}, {maximum})\n",
        "        \n",
        "The maximum is {maximum - mean} away from the mean\n",
        "The minimum is {mean - minimum} away from the mean\n",
        "            ''')\n",
        "            print('---------------------------------------------------')\n",
        "        elif self.cleaned[series].dtype == 'O':\n",
        "            mode = self.cleaned[series].mode()\n",
        "            print(f'The most freqent class is: {mode[0]}')\n",
        "            print('---------------------------------------------------')\n",
        "            \n",
        "            print(f'Value Counts for column: {self.cleaned[series].name}')\n",
        "            print(self.cleaned[series].value_counts())\n",
        "            print('---------------------------------------------------')\n",
        "        \n",
        "        # Number of NaN values\n",
        "        nans = self.cleaned[series].isna().sum()\n",
        "        nans_to_percent = nans/len(self.cleaned[series] * 100)\n",
        "        print(f'Number of NaNs: {nans}')\n",
        "        print(f'Percent of Null Values for the column: {nans_to_percent}%')\n",
        "        print('---------------------------------------------------')\n",
        "        \n",
        "        # Number of Unique Values - Only display if there are less than 20 unique\n",
        "        unique = self.cleaned[series].unique()\n",
        "        print(f'There are {len(unique)} values')\n",
        "        \n",
        "        if len(unique) <= 20:\n",
        "            print('Unique Values:')\n",
        "            print(unique)\n",
        "            print('---------------------------------------------------')\n",
        "        else:\n",
        "            print('Warning: High Cardinality')\n",
        "            print('---------------------------------------------------')\n",
        "\n",
        "    def train_val_test_split(self, X, y, random_state, test_size=0.20, val_size=0.25):\n",
        "        '''\n",
        "        Performs two train_test_splits on the dataset returning X and y for\n",
        "        train, validation and test sets.\n",
        "        Parameters:\n",
        "            - X: Feature data as a Pandas.DataFrame object\n",
        "            - y: Target column data as a Pandas.Series object\n",
        "            - random_state: Int value applied to the random_state parameter\n",
        "                            of both train_test_split calls.\n",
        "            - test_size (default=0.20): Percentage (0-1) representing a\n",
        "                        proportion of the (X, y) data PRIOR to first split.\n",
        "            - val_size (default=0.25): Percentage (0-1) representing a\n",
        "                        proportion of the (X, y) data POST first split.\n",
        "        \n",
        "        Returns (in order):\n",
        "            - X_train, y_train, X_val, y_val, X_test, y_test\n",
        "        '''\n",
        "\n",
        "        X_remain, X_test, y_remain, y_test = train_test_split(X, y, test_size=test_size,\n",
        "                                                              random_state=random_state)\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_remain, y_remain, test_size=val_size,\n",
        "                                                          random_state=random_state)\n",
        "\n",
        "        return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "    def make_conditions(self):\n",
        "\n",
        "        # 1. LotArea > 95-percentile (17401.15 ftsq)\n",
        "        condition_LotArea = (self.cleaned['LotArea'] <= 17401.15)\n",
        "\n",
        "        # 2. TotalBsmtSF > 1753\n",
        "        condition_TotalBsmtSF = (self.cleaned['TotalBsmtSF'] <= 1753)\n",
        "\n",
        "        # 3. 1stFlrSF > 1831.25\n",
        "        condition_1stFlrSF = (self.cleaned['1stFlrSF'] <= 1831.25)\n",
        "\n",
        "        # 4. GrLivArea > 2466.1\n",
        "        condition_GrLivArea = (self.cleaned['GrLivArea'] <= 2466.1)\n",
        "\n",
        "        # 5. SalePrice > 326100\n",
        "        condition_SalePrice = (self.cleaned['SalePrice'] <= 326100)\n",
        "\n",
        "        return [condition_LotArea, condition_TotalBsmtSF, condition_1stFlrSF, condition_GrLivArea, condition_SalePrice]\n",
        "\n",
        "    def clean_df(self, condition_LotArea=None, condition_TotalBsmtSF=None, condition_1stFlrSF=None, condition_GrLivArea=None, condition_SalePrice=None):\n",
        "        '''\n",
        "        This cleans up the dataframe, makes a few features and ordinally encodes some categorical features.\n",
        "        \n",
        "        Returns a DataFrame for Train or Test set depending on whether conditionals were given - default is for Test\n",
        "        '''\n",
        "\n",
        "        # First, remove all NaN values\n",
        "        condition0 = (len(self.cleaned) * 0.1)\n",
        "        cols = self.cleaned.columns\n",
        "\n",
        "        for col in cols:\n",
        "            n_NaN = (self.cleaned[col].isna().sum())\n",
        "            if n_NaN > condition0:\n",
        "                self.cleaned.drop(columns=col, inplace=True)\n",
        "            elif 0 < n_NaN < condition0:\n",
        "                if self.cleaned[col].dtype != 'O':\n",
        "                    if len(self.cleaned[col].unique()) > 20:\n",
        "                        self.cleaned[col].fillna(value=self.cleaned[col].mean(), inplace=True)\n",
        "                    else:\n",
        "                        self.cleaned[col].fillna(value=self.cleaned[col].mode()[0], inplace=True)\n",
        "                else:\n",
        "                    self.cleaned[col].fillna(value=self.cleaned[col].mode()[0], inplace=True)\n",
        "\n",
        "        # 1. LotShape - (Combine Irregular)\n",
        "        self.cleaned.loc[self.cleaned['LotShape'].str.startswith('IR'), 'RegularLotShape'] = 0\n",
        "        self.cleaned.loc[self.cleaned['LotShape'].str.startswith('Reg'), 'RegularLotShape'] = 1\n",
        "\n",
        "        # 2. LandContour - (Combine non Lvl values)\n",
        "        self.cleaned.loc[(self.cleaned['LandContour'] == 'Bnk') | (self.cleaned['LandContour'] == 'HLS') | (self.cleaned['LandContour'] == 'Low'), 'LandIsLvl'] = 0\n",
        "        self.cleaned.loc[self.cleaned['LandContour'] == 'Lvl', 'LandIsLvl'] = 1\n",
        "\n",
        "        # 3. LotConfig - (FR2, FR3 essentially the same)\n",
        "        # Ordinality - {'Inside': 0, 'Corner': 1, 'CulDSac': 2, 'FR': 3}\n",
        "        self.cleaned.loc[self.cleaned['LotConfig'] == 'Inside', 'LotConfigCL'] = 0\n",
        "        self.cleaned.loc[self.cleaned['LotConfig'] == 'Corner', 'LotConfigCL'] = 1\n",
        "        self.cleaned.loc[self.cleaned['LotConfig'] == 'CulDSac', 'LotConfigCL'] = 2\n",
        "        self.cleaned.loc[self.cleaned['LotConfig'].str.startswith('FR'), 'LotConfigCL'] = 3\n",
        "\n",
        "        # 4. Condition1 - (Combine adjacency types)\n",
        "        # Ordinality - {'Norm': 0, 'Feedr/Artery': 1, 'RRA/N': 2, 'PosFeat': 3}\n",
        "        self.cleaned.loc[self.cleaned['Condition1'] == 'Norm', 'LotAdjacencyType'] = 0\n",
        "        self.cleaned.loc[(self.cleaned['Condition1'] == 'Feedr') | (self.cleaned['Condition1'] == 'Artery'), 'LotAdjacencyType'] = 1\n",
        "        self.cleaned.loc[self.cleaned['Condition1'].str.startswith('RR'), 'LotAdjacencyType'] = 2\n",
        "        self.cleaned.loc[self.cleaned['Condition1'].str.startswith('Pos'), 'LotAdjacencyType'] = 3\n",
        "\n",
        "        # 5. OverallQual - (Combine extremes)\n",
        "        # Ordinality - {'below_4': 0, 'Average(4,5,6)': 1, 'above_6': 2}\n",
        "        self.cleaned.loc[self.cleaned['OverallQual'] < 4, 'HouseCondition'] = 0\n",
        "        self.cleaned.loc[self.cleaned['OverallQual'] <= 6, 'HouseCondition'] = 1\n",
        "        self.cleaned.loc[self.cleaned['OverallQual'] >= 7, 'HouseCondition'] = 2\n",
        "\n",
        "        # 6. YearBuilt - Split {MadeBefore1946: 0, MadeAfter1946: 1}\n",
        "        self.cleaned.loc[self.cleaned['YearBuilt'] < 1946, 'YrBuilt'] = 0\n",
        "        self.cleaned.loc[self.cleaned['YearBuilt'] >= 1946, 'YrBuilt'] = 1\n",
        "\n",
        "        # 7. YearRemodAdd - NEW COLUMN - WasRemodeled\n",
        "        # Process - If the years for YearBuilt and YearRemodAdd are the same, there was no remodel\n",
        "        self.cleaned.loc[self.cleaned['YearBuilt'] == self.cleaned['YearRemodAdd'], 'WasRemodeled'] = 0\n",
        "        self.cleaned.loc[self.cleaned['YearBuilt'] != self.cleaned['YearRemodAdd'], 'WasRemodeled'] = 1\n",
        "\n",
        "        # 8. MasVnrType - (Combine brick-types)\n",
        "        # Ordinality - {'None': 0, 'Brick': 1, 'Stone': 3}\n",
        "        self.cleaned.loc[self.cleaned['MasVnrType'] == 'None', 'VeneerType'] = 0\n",
        "        self.cleaned.loc[self.cleaned['MasVnrType'].str.startswith('Brk'), 'VeneerType'] = 1\n",
        "        self.cleaned.loc[self.cleaned['MasVnrType'] == 'Stone', 'VeneerType'] = 2\n",
        "\n",
        "        # 9. HeatingQC - (Combine Fair and Poor - heating is important!)\n",
        "        # Ordinality - {'Excellent': 0, 'Average': 1, 'Good': 2, 'Poor': 3}\n",
        "        self.cleaned.loc[self.cleaned['HeatingQC'] == 'Ex', 'HeatingQuality'] = 0\n",
        "        self.cleaned.loc[self.cleaned['HeatingQC'] == 'TA', 'HeatingQuality'] = 1\n",
        "        self.cleaned.loc[self.cleaned['HeatingQC'] == 'Gd', 'HeatingQuality'] = 2\n",
        "        self.cleaned.loc[(self.cleaned['HeatingQC'] == 'Fa') | (self.cleaned['HeatingQC'] == 'Po'), 'HeatingQuality'] = 3\n",
        "\n",
        "        # 10. Electrical - (Combine all Fuse types)\n",
        "        # Binary - {'Breaker': 0, 'Fuse': 1}\n",
        "        self.cleaned.loc[self.cleaned['Electrical'] == 'SBrkr', 'EleSystem'] = 0\n",
        "        self.cleaned.loc[(self.cleaned['Electrical'].str.startswith('Fuse')) | (self.cleaned['Electrical'] == 'Mix'), 'EleSystem'] = 1\n",
        "\n",
        "        # 11. BsmtFull/HalfBath - NEW COLUMN - BsmtHasBath\n",
        "        self.cleaned.loc[(self.cleaned['BsmtFullBath'] == 0) | (self.cleaned['BsmtHalfBath'] == 0), 'BsmtHasBath'] = 0\n",
        "        self.cleaned.loc[(self.cleaned['BsmtFullBath'] > 0) | (self.cleaned['BsmtHalfBath'] > 0), 'BsmtHasBath'] = 1\n",
        "\n",
        "        # 12. HalfBath - (Combine 1 and 2 to make binary) - HasHalfBath\n",
        "        self.cleaned.loc[self.cleaned['HalfBath'] == 0, 'HasHalfBath'] = 0\n",
        "        self.cleaned.loc[self.cleaned['HalfBath'] > 0, 'HasHalfBath'] = 1\n",
        "\n",
        "        # 13. BedroomAbvGr - (0-1, 2, 3, 4+)\n",
        "        # Ordinality - {'less_than_2': 0, '2': 1, '3': 2, '4+': 3}\n",
        "        self.cleaned.loc[self.cleaned['BedroomAbvGr'] < 2, 'Bedrooms'] = 0\n",
        "        self.cleaned.loc[self.cleaned['BedroomAbvGr'] == 2, 'Bedrooms'] = 1\n",
        "        self.cleaned.loc[self.cleaned['BedroomAbvGr'] == 3, 'Bedrooms'] = 2\n",
        "        self.cleaned.loc[self.cleaned['BedroomAbvGr'] > 3, 'Bedrooms'] = 3\n",
        "\n",
        "        # 14. TotRmsAvbGrd - NEW COLUMN - AdditionalRooms\n",
        "        # Make a new column called RemainingRooms that is the difference between Total Rooms and Bedrooms\n",
        "        # Ordinality - {'less_than_3': 0, '3': 1, '4': 2, '5': 3, 'more_than_5': 4}\n",
        "        self.cleaned['RemainingRooms'] = self.cleaned['TotRmsAbvGrd'] - self.cleaned['BedroomAbvGr']\n",
        "        self.cleaned.loc[self.cleaned['RemainingRooms'] < 3, 'AdditionalRooms'] = 0\n",
        "        self.cleaned.loc[self.cleaned['RemainingRooms'] == 3, 'AdditionalRooms'] = 1\n",
        "        self.cleaned.loc[self.cleaned['RemainingRooms'] == 4, 'AdditionalRooms'] = 2\n",
        "        self.cleaned.loc[self.cleaned['RemainingRooms'] == 5, 'AdditionalRooms'] = 3\n",
        "        self.cleaned.loc[self.cleaned['RemainingRooms'] > 5, 'AdditionalRooms'] = 4\n",
        "\n",
        "        # 15. Fireplaces - (Combine 2 and 3)\n",
        "        # Ordinality - {'None': 0, '1': 1, '2+': 2}\n",
        "        self.cleaned.loc[self.cleaned['Fireplaces'] == 0, 'NumFireplaces'] = 0\n",
        "        self.cleaned.loc[self.cleaned['Fireplaces'] == 1, 'NumFireplaces'] = 1\n",
        "        self.cleaned.loc[self.cleaned['Fireplaces'] > 1, 'NumFireplaces'] = 2\n",
        "\n",
        "        # 16. GarageCars - (Combine 3 and 4)\n",
        "        # Ordinality - {'0': 0, '1': 1, '2': 2, '3+': 3}\n",
        "        self.cleaned.loc[self.cleaned['GarageCars'] == 0, 'GarageAreaByCar'] = 0\n",
        "        self.cleaned.loc[self.cleaned['GarageCars'] == 1, 'GarageAreaByCar'] = 1\n",
        "        self.cleaned.loc[self.cleaned['GarageCars'] == 2, 'GarageAreaByCar'] = 2\n",
        "        self.cleaned.loc[self.cleaned['GarageCars'] > 2, 'GarageAreaByCar'] = 3\n",
        "\n",
        "        # 17. WoodDeckSF - NEW COLUMN - HasDeck\n",
        "        self.cleaned.loc[self.cleaned['WoodDeckSF'] == 0, 'HasDeck'] = 0\n",
        "        self.cleaned.loc[self.cleaned['WoodDeckSF'] > 0, 'HasDeck'] = 1\n",
        "\n",
        "        # 18. PoolArea - NEW COLUMN - HasPool\n",
        "        self.cleaned.loc[self.cleaned['PoolArea'] == 0, 'HasPool'] = 0\n",
        "        self.cleaned.loc[self.cleaned['PoolArea'] > 0, 'HasPool'] = 1\n",
        "\n",
        "        # 19. MoSold - Subtract all items by 1\n",
        "        # Ordinality - {'Jan': 0 ... 'Dec': 11}\n",
        "        self.cleaned['MonthSold'] = self.cleaned['MoSold'] - 1\n",
        "\n",
        "        # 20. YrSold - Convert years to 0-4 - 2010 might not have concluded at creation of dataset\n",
        "        # Ordinality - {'2006': 0, '2007': 1, '2008': 2, '2009': 3, '2010': 4}\n",
        "        self.cleaned.loc[self.cleaned['YrSold'] <= 2006, 'YearSold'] = 0\n",
        "        self.cleaned.loc[self.cleaned['YrSold'] == 2007, 'YearSold'] = 1\n",
        "        self.cleaned.loc[self.cleaned['YrSold'] == 2008, 'YearSold'] = 2\n",
        "        self.cleaned.loc[self.cleaned['YrSold'] == 2009, 'YearSold'] = 3\n",
        "        self.cleaned.loc[self.cleaned['YrSold'] == 2010, 'YearSold'] = 4\n",
        "        \n",
        "        # =====================================================================================\n",
        "\n",
        "        new_columns = list(self.cleaned.columns[-21:])\n",
        "\n",
        "        features_encoded = self.cleaned[new_columns].astype('int64')\n",
        "\n",
        "        if condition_LotArea != None:\n",
        "\n",
        "            df_inter = pd.concat([self.cleaned[['LotArea', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'SalePrice']], features_encoded], axis=1)\n",
        "\n",
        "            # Final data set should be shape (1253, 26)\n",
        "\n",
        "            final_clean_filtered = df_inter[condition_LotArea & condition_TotalBsmtSF & condition_1stFlrSF & condition_GrLivArea & condition_SalePrice]\n",
        "\n",
        "            return final_clean_filtered  # Specifically for Train data set\n",
        "        \n",
        "        else:\n",
        "            \n",
        "            df_inter = pd.concat([self.cleaned[['Id', 'LotArea', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea']], features_encoded], axis=1)\n",
        "\n",
        "            return df_inter  # This is specifically for the Test data set (does not have SalePrice)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvu6DTnCWYhY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import make_scorer, mean_squared_log_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def rmsle(pred, true):\n",
        "  return mean_squared_log_error(pred, true) ** 0.5\n",
        "\n",
        "\n",
        "scorer = make_scorer(rmsle, greater_is_better=False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqp4WBdmUir9",
        "outputId": "93fb6349-34e3-4f08-f339-6fbf5ef16842"
      },
      "source": [
        "train = Train(pd.read_csv(TRAIN_URL))\n",
        "test = Train(pd.read_csv(TEST_URL))\n",
        "\n",
        "# Split the data\n",
        "X = train.cleaned.drop(columns='SalePrice')\n",
        "y = train.cleaned['SalePrice']\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = train.train_val_test_split(\n",
        "    X=X, y=y, random_state=42\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_val.shape,\n",
        "      y_val.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(751, 25) (751,) (251, 25) (251,) (251, 25) (251,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G71hQR_TVapy"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [_ for _ in range(50, 501, 50)],\n",
        "    'max_depth': [_ for _ in range(1, 12)],\n",
        "    'learning_rate': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "    'booster': ['gbtree', 'gblinear', 'dart'],\n",
        "    'tree_method': ['auto', 'exact', 'approx', 'hist', 'gpu_hist'],\n",
        "    'gamma': [1, 10, 100, 1000, 1e4, 1e5],\n",
        "    'min_child_weight': [_ for _ in range(1, 11)],\n",
        "    'min_delta_step': [_ for _ in range(11)],\n",
        "    'subsample': [0.25, 0.5, 0.75, 1],\n",
        "    'reg_alpha': [0, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10, 15, 20, 30, 40, 50, 100],\n",
        "    'reg_lambda': [0.001, 0.01, 0.1, 1, 5, 10, 15, 20, 30, 40, 50, 100]\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8sPf426cNbv",
        "outputId": "268cf872-c140-4ca8-a199-984adf7fea6b"
      },
      "source": [
        "xgbr = XGBRegressor()\n",
        "\n",
        "rs = RandomizedSearchCV(xgbr, param_distributions=param_grid, n_iter=100,\n",
        "                        n_jobs=-1, cv=10, verbose=10)\n",
        "rs"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10, error_score=nan,\n",
              "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
              "                                          colsample_bylevel=1,\n",
              "                                          colsample_bynode=1,\n",
              "                                          colsample_bytree=1, gamma=0,\n",
              "                                          importance_type='gain',\n",
              "                                          learning_rate=0.1, max_delta_step=0,\n",
              "                                          max_depth=3, min_child_weight=1,\n",
              "                                          missing=None, n_estimators=100,\n",
              "                                          n_jobs=1, nthread=None,\n",
              "                                          objective='reg:linear',\n",
              "                                          random_state=0, reg_alpha...\n",
              "                                        'n_estimators': [50, 100, 150, 200, 250,\n",
              "                                                         300, 350, 400, 450,\n",
              "                                                         500],\n",
              "                                        'reg_alpha': [0, 0.0001, 0.001, 0.01,\n",
              "                                                      0.1, 1, 5, 10, 15, 20, 30,\n",
              "                                                      40, 50, 100],\n",
              "                                        'reg_lambda': [0.001, 0.01, 0.1, 1, 5,\n",
              "                                                       10, 15, 20, 30, 40, 50,\n",
              "                                                       100],\n",
              "                                        'subsample': [0.25, 0.5, 0.75, 1],\n",
              "                                        'tree_method': ['auto', 'exact',\n",
              "                                                        'approx', 'hist',\n",
              "                                                        'gpu_hist']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwuxMqEccOFO",
        "outputId": "9bdffc1c-fd99-473f-84d6-e2d17231d050"
      },
      "source": [
        "rs.fit(X_train, y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    4.1s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1807s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0695s.) Setting batch_size=1.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   18.1s\n",
            "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   20.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1880s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:   20.9s\n",
            "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   22.8s\n",
            "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:   24.5s\n",
            "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed:   27.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too slow (3.2369s.) Setting batch_size=1.\n",
            "[Parallel(n_jobs=-1)]: Done 254 tasks      | elapsed:   58.2s\n",
            "[Parallel(n_jobs=-1)]: Done 273 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1929s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too slow (7.1226s.) Setting batch_size=1.\n",
            "[Parallel(n_jobs=-1)]: Done 308 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1914s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0402s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done 392 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1056s.) Setting batch_size=1.\n",
            "[Parallel(n_jobs=-1)]: Done 429 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=-1)]: Done 454 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done 481 tasks      | elapsed:  2.5min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=-1)]: Done 566 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1975s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1348s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too slow (2.6645s.) Setting batch_size=1.\n",
            "[Parallel(n_jobs=-1)]: Done 650 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=-1)]: Done 689 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1694s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0420s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too slow (18.9039s.) Setting batch_size=1.\n",
            "[Parallel(n_jobs=-1)]: Done 738 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done 773 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=-1)]: Done 808 tasks      | elapsed:  5.4min\n",
            "[Parallel(n_jobs=-1)]: Done 845 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=-1)]: Done 882 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=-1)]: Done 921 tasks      | elapsed:  5.7min\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1866s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1304s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too slow (13.7156s.) Setting batch_size=1.\n",
            "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:  6.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  6.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[22:20:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10, error_score=nan,\n",
              "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
              "                                          colsample_bylevel=1,\n",
              "                                          colsample_bynode=1,\n",
              "                                          colsample_bytree=1, gamma=0,\n",
              "                                          importance_type='gain',\n",
              "                                          learning_rate=0.1, max_delta_step=0,\n",
              "                                          max_depth=3, min_child_weight=1,\n",
              "                                          missing=None, n_estimators=100,\n",
              "                                          n_jobs=1, nthread=None,\n",
              "                                          objective='reg:linear',\n",
              "                                          random_state=0, reg_alpha...\n",
              "                                        'n_estimators': [50, 100, 150, 200, 250,\n",
              "                                                         300, 350, 400, 450,\n",
              "                                                         500],\n",
              "                                        'reg_alpha': [0, 0.0001, 0.001, 0.01,\n",
              "                                                      0.1, 1, 5, 10, 15, 20, 30,\n",
              "                                                      40, 50, 100],\n",
              "                                        'reg_lambda': [0.001, 0.01, 0.1, 1, 5,\n",
              "                                                       10, 15, 20, 30, 40, 50,\n",
              "                                                       100],\n",
              "                                        'subsample': [0.25, 0.5, 0.75, 1],\n",
              "                                        'tree_method': ['auto', 'exact',\n",
              "                                                        'approx', 'hist',\n",
              "                                                        'gpu_hist']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5cbBHwhd7zX",
        "outputId": "420ba321-231e-4364-9565-da1e1e64581c"
      },
      "source": [
        "rs.best_params_"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'booster': 'gbtree',\n",
              " 'gamma': 1000,\n",
              " 'learning_rate': 0.1,\n",
              " 'max_depth': 8,\n",
              " 'min_child_weight': 9,\n",
              " 'min_delta_step': 0,\n",
              " 'n_estimators': 350,\n",
              " 'reg_alpha': 5,\n",
              " 'reg_lambda': 100,\n",
              " 'subsample': 0.5,\n",
              " 'tree_method': 'approx'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4XxTqMMfQOI",
        "outputId": "025f64bc-8aba-4473-f594-ca2f880a4fc0"
      },
      "source": [
        "y_pred_test = rs.predict(X_test)\n",
        "y_pred_val = rs.predict(X_val)\n",
        "\n",
        "rmsle_test = mean_squared_log_error(y_test, y_pred_test) ** 0.5\n",
        "rmsle_val = mean_squared_log_error(y_val, y_pred_val) ** 0.5\n",
        "print(f'Test RMSLE: {rmsle_test}')\n",
        "print(f'Val RMSLE: {rmsle_val}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test RMSLE: 0.14625599544544843\n",
            "Val RMSLE: 0.15420556549878434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "F7FxvOnYfkDr",
        "outputId": "69e113b7-a252-4668-801b-ab120fa18ee0"
      },
      "source": [
        "cleaned_df = test.clean_df()\n",
        "\n",
        "IDs = cleaned_df['Id']\n",
        "feat = cleaned_df[cleaned_df.columns[1:]]\n",
        "\n",
        "y_pred = rs.predict(feat)\n",
        "submission_rs_xgbr = pd.DataFrame({'Id': IDs, 'SalePrice': y_pred})\n",
        "submission_rs_xgbr.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>109771.031250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>150588.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>182100.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>176627.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>185286.390625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Id      SalePrice\n",
              "0  1461  109771.031250\n",
              "1  1462  150588.562500\n",
              "2  1463  182100.250000\n",
              "3  1464  176627.687500\n",
              "4  1465  185286.390625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCSA8hVfglA9"
      },
      "source": [
        "submission_rs_xgbr.to_csv('submission_rs_xgbr0.csv', index=False)"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}